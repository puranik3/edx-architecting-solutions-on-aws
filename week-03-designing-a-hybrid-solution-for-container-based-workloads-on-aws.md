# Week 3 - Designing a hybrid solution for container based workloads on AWS

## Week 3 Introduction
- enterprise customer working in insurance business is migrating containers to AWS

## Customer #3: Use Case and Requirements
- half of contracts on existing on-premises data center provider expired
    - this half has to be moved to AWS
    - remaining half will stay on-premises for a couple more years
    - they have to communicate with each other
    - i.e. customer is looking for a __hybrid deployment__ with AWS
- customer requires lowest latency and consistent throughput in network between the 2 environments
- since apps are all internal, need to make sure the environments are not accessible via public internet
- on-premises resources will produces data which will need to be stored as files in AWS and accessed by apps in the AWS cloud
- customer currently uses container for all apps except DBs
    - plan to migrate a few PostgreSQL DBs to containers
    - but do not want to rewrite apps due to this migration - is there such a solution??
        - i.e. want a lift-and-shift for this part
- need to use same orchestration tools in both environments
- need high up-time (availability)

## Customer #3: Requirements Breakdown
- container services to be explored
- host PostreSQL DB on AWS
- same tools for container orchestration in 2 environments
- store data generated on-premises in AWS with minimal refactoring (needs further discussion with customer)
- optimize for resilience
    - needs to be fault-tolerant - llok out for single points of failure
- customer does not want to change app
    - more of lift-and-shift migration needed
    - luckily containers are portable in nature!
        - migration, especially lift-and-shift, should not be much of an issue

## Hybrid Networking and Connectivity Services
- when designing the solution, we need to think about "service blocks" to be placed on both on-premises side and AWS cloud side
- Since apps are not publicly accessible, we shall go in for larger private subnets
- __Candidates for network connectivity__ between on-prem and AWS
    - __public internet__
        - non-encrypted, no security
            - company has internal apps and is into insurance - need more security
        - throughput is at the mercy of the internet
            - company needs low latency for apps
        - rejected!
    - __AWS VPN__
        - 2 types of AWS VPNs
            - __site-to-site VPN__
                - connects on-prem to VPC
            - __client VPN__
                - connects users (like network admins, ops, devs etc.) to VPC
        - encrypted
            - good
        - throughput is at the mercy of the internet
            - bad - company needs low latency for apps
        - rejected!
    - __AWS Direct Connect__
        - private dedicated connection
            - traffic remains on AWS global network and never on public internet
            - secure
            - low latency
    - So...__AWS Direct Connect__ is the winner
- for simplicity we assume on AWS side
    - 1 account
    - 1 VPC
    - 1 Region
    - we may decide to change the design later if needed
    - If the customer needs to work with __multiple AWS accounts__, or __regions__ we need an __AWS Transit Gateway__

## Reading 3.1: Hybrid Networking and Connectivity
- __AWS Direct Connect__
    - consistent, dedicated throughput for the high volume of data that flows between the data center and AWS
    - shortest path to your AWS resources
        - while your network traffic is in transit, it remains on the AWS global network and never touches the public internet
        - low latency
    - you can choose
        - __hosted connection__
            - provided by an AWS Direct Connect Delivery Partner
        - __dedicated connection from AWS__
            - deploy at over 100 AWS Direct Connect locations around the globe
            - __AWS Direct Connect SiteLink__
                - send data between AWS Direct Connect locations to create private network connections between the offices and data centers in your global network
                - each dedicated AWS Direct Connect connection consists of
                    - a single dedicated connection between ports on your router and an AWS Direct Connect device
                    - we recommend establishing a second connection for redundancy
                    - when you request multiple ports at the same AWS Direct Connect location, they will be provisioned on redundant AWS equipment
        - if you have configured a __backup__ __Internet Protocol security (IPSec) VPN__ connection instead, __all VPC traffic will fail over to the VPN connection automatically__
            - traffic to or from public resources, such as S3, will be routed over the internet
        - If you __don't have a backup AWS Direct Connect link or an IPSec VPN link__, then __VPC traffic will be dropped if a failure occurs__
            - traffic to or from public resources, such as S3, will be routed over the internet
- __AWS Managed VPN__
    - __AWS Site-to-Site VPN__
        - by default, __instances that you launch into a VPC can't communicate with your own on-premises network__
        - enable access to your network from your VPC by creating AWS Site-to-Site VPN connection
        - Site-to-Site VPN supports __IPSec VPN connections__
        - __Virtual Private Gateway (VPG)__
            - the VPN concentrator on the Amazon side of the Site-to-Site VPN connection
                - attach it to the VPC where you want to create the Site-to-Site VPN connection
            - on the customer end, there is/are a _customer gateway device(s)_ (physical or software) owned and managed by the customer
                - attach it to the on-premises network
                - connects to the VPG over the IPSec VPN
            - consider taking this approach when you want to take advantage of an AWS managed VPN endpoint that includes automated redundancy and failover built into the AWS side of the VPN connection
                - supports and encourages multiple user gateway connections that implement redundancy and failover on your side of the VPN connection
    - __AWS Client VPN__
        - __fully managed__, remote-access VPN solution that your remote workforce can use to securely access resources within both AWS and your on-premises network
        - __fully elastic__
        - AWS Client VPN, including the software client, __supports the OpenVPN protocol__
        - __Use cases__
            - __Note__: Refer to diagrams from the course to understand these use cases
            - The configuration for this scenario includes a single target VPC. We recommend this configuration if you need to give clients access to the resources inside only a single VPC.
            - The configuration for this scenario includes access to only an on-premises network. We recommend this configuration if you need to give clients access to the resources inside only an on-premises network.
            - In the configuration for the scenario shown in the following diagram, clients can access a single VPC, and clients can also route traffic to each other. We recommend this configuration if the clients that connect to the same client VPN endpoint also need to communicate with each other. Clients can communicate with each other by using the unique IP address that's assigned to them from the client Classless Inter-Domain Routing (CIDR) range when they connect to the client VPN endpoint.
- __AWS Transit Gateway__
    - if multiple regions or AWS accounts were all connected to a remote data center by using AWS Direct Connect, it can be used
    - data is automatically encrypted and never travels over the public internet
    - __connects your VPCs and on-premises networks through a central hub__
        - simplifies your network and minimizes complex peering relationships
    - acts as a cloud router
        — each new connection is made only once
    - inter-region peering connects transit gateways together through the AWS global network
        - __Note__: Refer to diagrams from the course to understand these use scenarios
        - __Without AWS Transit Gateway__
            - The following diagram shows what a network solution might look like without the use of AWS Transit Gateway. Notice that there are many different connection points between the different components. This network configuration is complex, and it can be difficult to manage.
        - __With AWS Transit Gateway__
            - In contrast, the following diagram shows what a network solution might look like with the use of AWS Transit Gateway. Transit Gateway is the hub for the connections between the different networks. Using a transit gateway can make the network easier to manage. You can apply route tables so that the transit gateway can connect networks to each other in a more centralized manner.
            - The following example shows what using AWS Transit Gateway with AWS Direct Connect could look like for a solution that has a remote network and three AWS Regions. Each Region has multiple VPCs.

## Running Containers on AWS
- container orchestration tools
    - help create, scale up, delete containers, and manage them in general
- AWS provides 2 services for container orchestration
    - ECS
    - EKS
- both services can be run in unmanaged (on EC2 instances) and fully-managed way (Fargate)
- EKS
    - uses Kubernetes (K8s)
        - K8s has a vibrant community
        - consisten open-source APIs
        - flexibility
        - uses K8s APIs
    - steep learning curve
        - good choice if already using K8s on-prem
        - not very convenient, but provides great control
- ECS
    - simple but opinionated (when it comes to network and security configurations, say)
        - for example you don't need to figure out which type of ELBs you need to connect to in ECS - it decides
    - designed to be convenient, while trading off control
    - deep integrations to AWS services such as VPC, load balancing, service discovery, and IAM roles
    - uses AWS (ECS) APIs
- Again for choice of compute (EC2/Fargate) you can consider convenience vs. control
    - eg. you do not get access to the underlying instances in Fargate
- So, which ones to use?
    - ask the customer!
    - __customer says they have huge number of container but aren't doing any complicated with them__
    - __Their team tried learning K8s in the past but it was overwhelming__
    - __They would like to SSH into the servers__
    - A simpler solution will suffice!
- So...ECS with EC2 is the winner
    - scalable but simple!
    - can access underlying compute infrastructure through SSH
    - choose ECS service
    - choose EC2 instances to be in a private subnet
        - without internet connectivity - neither ingress nor egress
        - but __EC2 instances in the private subnet may need to download from the internet__ (especially when they spin up and install software)
            - add a __Network Address Translation (NAT)__ in a __public subnet in the same VPC__
                - __Two options for NAT__
                    - __NAT instance__
                        - unmanaged
                        - NAT software installed on an EC2 instance
                        - performance and throughput based off of underlying EC2 instance size and type
                        - you also need to host multiple NAT instances in each AZ, and also manage failover via scripts
                        - good for someone with smaller workload as it can reduce costs (if managed well)
                    - __NAT gateway__
                        - managed and massively scalable
                        - a serverless NAT service
                        - good choice for enterprise which has large worloads
            - we __choose NAT gateway__ over NAT instance in this case

## Reading 3.2: Running Containers on AWS and NAT Gateways
- requirement is containers
    - running internal apps
    - don't require inbound communication from the internet
    - require outbound communication to the internet
    - need own custom Amazon Machine Image (AMI) for the cluster that hosts the containers
    - also have SSH access to underlying instances
- hence choice is __ECS as the container orchestration tool__ and __EC2 as the launch type__
- include a NAT gateway so that private instances could download from the internet

### Amazon ECS launch types
- __EC2__
    - deploy and manage your own cluster of EC2 instances (you register those instance to your ECS cluster)
    - an ECS agent is installed on each EC2 instance
        - enables the orchestration tool that ECS uses to manage nodes
- __Fargate__
    - run containers directly, without self-provisioned EC2 instances
- EC2 launch type is suitable as customer wants to use
    - a custom AMI
    - SSH to access underlying instances
- https://docs.aws.amazon.com/AmazonECS/latest/developerguide/launch_types.html

### NAT devices
- a NAT device allow resources in private subnets to connect to
    - the internet
    - other VPCs
    - on-premise networks
- can communicate with services outside the VPC, but they can't receive unsolicited connection requests
    - __NAT device replaces the source IPv4 address of the instances with the address of the NAT device__
    - __sends response traffic to the instances__, and __translates the addresses back to the original source IPv4 addresses__
- Two options
    - __NAT gateway__
        - managed NAT device offered by AWS
    - __NAT instance__
        - your own NAT device on an EC2 instance
    - recommended is NAT gateways because they
        - are managed
            - provide better availability and bandwidth
            - automatically scalable
            - help in administration
- __manage how the traffic flows from the private resources to the NAT device__ by using __route tables__
- __Connectivity types__
    - when you create a NAT gateway, you specify one of the following connectivity types
    - __Public (default)__
        - instances in private subnets can connect to the internet through a public NAT gateway
        - they can't receive unsolicited inbound connections from the internet
            - __you create a public NAT gateway in a public subnet__
            - you __must associate an elastic IP address with the NAT gateway__ at creation
            - you route traffic from the NAT gateway to the internet gateway for the VPC
                - alternatively, you can use a public NAT gateway to connect to other VPCs or your on-premises network
                - here, you route traffic from the NAT gateway through a transit gateway or a virtual private gateway
    - __Private__
        - instances in private subnets can connect to other VPCs or your on-premises network through a private NAT gateway
        - you can route traffic from the NAT gateway through a transit gateway or a virtual private gateway
        - __you can't associate an elastic IP address with a private NAT gateway__
        - you can attach an internet gateway to a VPC with a private NAT gateway, but if you route traffic from the private NAT gateway to the internet gateway, the internet gateway drops the traffic!
- The NAT gateway replaces the source IP address of the instances with the IP address of the NAT gateway
    - for a public NAT gateway, this is the elastic IP address of the NAT gateway
    - for a private NAT gateway, this is the private IP address of the NAT gateway
- https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html

## Amazon Relational Database Service (RDS)
- RDS has __Multi-AZ deployment__
    - one is a __primary instance__, and the other a __secondary instance__
        - primary is the only writer
    - synchronous replication for non-Aurora RDBMS
    - asynchronous replication for Aurora
    - apps connect via a DNS, and in a failover RDS manages the DNS record changes
- RDS supports __Read Replicas__
    - asynchronous replication
    - business application can use the primary instance, and BI applications can use the Read Replicas, say
    - __Cross-Region Read Replicas__ also supported
- in this case, customer needs to migrate DB
- AWS __Database Migration Service (AWS DMS)__ can be used
    - can migrate without downtime
    - you can __set on-prem DB as source and RDS DB as target__
        - now, the source data changes on-prem, it is continuously replicated to the target DB in AWS
        - you can switchover to the target DB whenever convenient
    - you have
        - __Homogeneous DB migrations__
            - eg. SQL DB to another SQL DB
        - __Heterogeneous DB migrations__
            - eg. SQL DB to NoSQL DB
            - aided by AWS Schema conversion tool
    - DMS can also be used to
        - keep development and test DBs in-sync with production
        - consolidate data from multiple DBs into one
        
## Amazon RDS Exploration
- Demo of RDS DB creation
    - while creating it you can enable auto-scaling for DB
    - __Performance Insights__
        - an advanced DB performance monitoring feature that diagnose and helps solve performance issues

## Reading 3.3: Amazon RDS

### Multi-AZ deployments
- Multi-AZ deployment
    - high availability
    - automatic failover
    - 2 AZs are used by default - 1 primary and 1 standby
        - for even higher availability, deploy 2 standby DB instances (total 3 AZs)
        - primary is the only writer, standbys are readers
        - automatic failovers typically happen in < 35 seconds
        - transaction-commit latency up to 2 times faster when compared to with with only 1 standby
        - also gain additional read capacity, and a choice of AWS Graviton2–based or Intel–based instances for compute

### Read replicas
- increases aggregate read throughput
- enhanced performance and durability
- for __read-heavy DB workloads__ this makes it easier to elastically scale out beyond the capacity constraints of a single DB instance
- highly available
- uses the engine's native __asynchronous replication__ to update the replicas when source changes
    - RDS replicates all DBs in the source DB instance
- read replica allows only read-only connections
- read replica can also be promoted to become standalone DB instance, when needed
- eg. say that you arere running reports on your DB, which is causing performance issues with CPU-intensive reads
    - create read replica and direct all the reporting queries to that

### Scaling Amazon RDS instances
- __Scale your instance up vertically__
    - When you create an RDS DB instance, you choose a database instance type and size
        - CPU, memory, storage, and networking capacity
    - Not every instance type is supported for every DB engine, version, edition or region
    - you can vertically scale the instance and choose a larger instance size
        - do this when need __more CPU and storage ability for an instance__
- __Use read replicas__
    - if you need __more CPU capabilities but do not need more storage__
- __Enable RDS Storage Auto Scaling__
    - If you __need more storage, but do not need more CPU__, then you could __scale the storage horizontally__
    - allocate more storage volumes manually, or by enabling __RDS Storage Auto Scaling__
        - when auto-scaling there is virtually zero downtime
            - you need to set your desired maximum storage limit
            - continuously monitors actual storage consumption, and scales when actual utilization approaches provisioned capacity
            - works with new and existing DB instances
- __Change the storage type for increased performance__
    - using __Provisioned IOPS instead of General Purpose__ could improve performance
    - __3 storage types__
        - __General Purpose SSD__
            - good for general workloads
            - single-digit millisecond latencies
            - ability to burst to 3,000 IOPS for extended periods of time
        - __Provisioned IOPS__
            - meet needs of __I/O-intensive workloads__
            — low I/O latency and consistent I/O throughput
        - __Magnetic__
            - for backward compatibility
            - __Note__: __NOT__ recommended usually

### AWS DMS
- helps migrate DBs to AWS quickly and securely
- At a basic level, AWS DMS is a server in the AWS Cloud that runs and replicates from source DB to target DB
- source DB can be
    - on-premises outside of AWS
    - on an EC2 instance
    - on RDS
- target DB can be
    - on an EC2 instance
    - on RDS
- __AWS Schema Conversion Tool (AWS SCT)__
    - to _create some or all of the target_ __tables__, __indexes__, __views__, __triggers__ etc.

## Where Should Our Customer Store Their Data?
- __Candidates__
    - S3
    - EFS
        - file storage for the cloud
        - uses Network File Storage (NFS) protocol
            - so multiple EC2 instances / containers can use an NFS volume at the same time
        - elastic
    - FSx
        - managed file storage
        - support for file systems like NetAPP ONTOP, OpenZFS, Windows File Server and Lustre
        - if customer if already using one of the filesystems for their storage, we could consider using this option
    - EBS
        - block storage
        - not managed for scaling
        - like virtual hard drives that can be attached to EC2 instances
        - good for block storage needs like DBs
- To decide which storage to use we need to understand about what kind of data shall be stored and how they shall be used
- So, which ones to use?
    - ask the customer!
    - data is generated by the app and stored in a filesystem on-prem
        - right now files are stores using NFS and would like to continue using it!
    - other apps do not change that data - they only read it
    - analytics processing and ML apps use them and those will soon be moved to AWS
    - data needs to be accessed frequenlty one till about a week after they are created
    - access decreases over time - after a year almost never accessed
    - would like to move files to appropriate storage to reduce costs
    - would also like to have lowest latency so files do not take a long time to upload over the internet
- __Candidates__
    - EFS
        - uses NFS
        - you can transfer files to it over Direct Connect
        - EFS supports lifecycle policies to move less frequently used data to lower cost tier
        - only problem is customer wants low latency
            - right now apps writing data are on-prem - so data has to travel from on-prem to EFS as it is generated and needs to be written
    - S3
        - AWS Storage Gateway
            - provides on-prem apps access to cloud storage
            - being an on-prem device, the gateway provides low latency for reads/writes
            - maintains a local cache of the data as well
            - 4 types
                - Amazon S3 File Gateway
                    - supports NFS, SMB protocol
                    - on-prem apps write to NFS filesystem on-prem and the gateway asynchronously syncs to S3
                - FSx File Gateway
                - Volume Gateway
                - Tape Gateway
- So...__Storage Gateway with S3__ is the winner
    - Due to support for NFS and low latency, and better support for tiering we choose this option

## Storage Gateway Exploration
- Demo on Storage Gateway AWS console

## Reading 3.4: AWS Storage Services
- Storage Gateway supports this use case
    - customer requires the Network File System (NFS) protocol to remain in place for all on-prem apps
    - customer also wants to store the files (that they will access) in AWS
- __AWS Storage Gateway__
- near-seamless integration with data security
- __Amazon S3 File Gateway__
- store and retrieve objects in S3 by using industry-standard file protocols, such as NFS (version 3 or version 4.1) and Server Message Block (SMB version 2 or version 3)
- combines a service and a virtual software appliance
    - software appliance (or gateway) is deployed into your on-premises environment as a virtual machine (VM) that runs on VMware ESXi, Microsoft Hyper-V, or Linux Kernel-based Virtual Machine (KVM) hypervisor
- supports a file interface into Amazon S3
    - provides access to objects in Amazon S3 as files or file-share mount points
    - think of a S3 File Gateway as a file system mount on Amazon S3
- manage your Amazon S3 data by using lifecycle policies, S3 Cross-Region Replication (CRR), and versioning
- provides low-latency access to data through transparent local caching
    - manages data transfer to and from AWS, and it optimizes and streams data in parallel
    - buffers applications from network congestion, and manages bandwidth consumption
- __Amazon EBS__
- flexible
    - for current-generation volumes attached to current-generation instance types, you can dynamically increase size, modify the provisioned IOPS capacity, and change volume type on live production volumes
- volume types
    - different volume types and sizes
    - IOPS are correlated with volume type and size
        - IOPs increases with the size of the volume
    - __Solid-state drives (SSD)__
        - for __transactional workloads__ involving __frequent read/write operations__ with __small I/O size__
            - dominant performance attribute is IOPS
        - SSD-backed volume types include
            - __General Purpose SSD volumes__
            - __Provisioned IOPS SSD volumes__
    - __Hard disk drives (HDD)__
        - for __large, streaming workloads__
            - dominant performance attribute is throughput
        - HDD-backed volume types include
            - __Throughput Optimized HDD__
            - __Cold HDD volumes__
    - __Previous generation__
        - for __workloads with small datasets__, where data is __accessed infrequently and performance is not a priority__
        - not recommended
- __Amazon EFS__
- simple, serverless elastic filesystem that you can use with AWS Cloud services and on-premises resources
    - reduce the complexity of deploying, patching, and maintaining complex file system configurations
- built to scale on demand to petabytes without disrupting applications
- can grow and shrink automatically as you add and remove files
- supports NFS version 4 (NFSv4.1 and NFSv4.0)
- Mmultiple compute instances—including Amazon EC2, Amazon Elastic Container Service (Amazon ECS), and AWS Lambda, __can access an Amazon EFS file system at the same time__
    - provides a common data source for workloads and applications that run on more than one compute instance or server
- __Amazon S3__
- object storage service
- store data with changing or unknown access patterns in S3 Intelligent-Tiering, which optimizes storage costs by automatically __moving your data between four access tiers when your access patterns change__
    - two low-latency access tiers, which are optimized for frequent and infrequent access
    - two opt-in archive access tiers that are designed for asynchronous access to rarely accessed data

## Hybrid Solutions on AWS
- customer wants to use the same operational tools on-prem and AWS cloud
- __very important part of being a Cloud Solutions Architect is the take care of migrations!__
- __AWS Outposts__
    - run AWS services on-prem
    - __hardware is delivered to you data center!__
        - AWS Outposts racks, servers etc.
    - great for very low latency, or compliance 
- 2 choices for containers
    - provide __consistent container orchestration tooling on-prem and AWS cloud__
    - reduces redundant effort
    - __Amazon ECS Anywhere__
    - __Amazon EKS Anywhere__
- Since we chose ECS already, __ECS Anywhere is the natural choice for on-prem__ in our case
- will require customer to redefine ane redeploy the container deployment on-prem
    - actual container itself will likely not change
- __Steps: How it works__
    - create and register an activation key to register the VMs you plan to use for the containers on-prem
    - install the __AWS Systems Manager (SSM) Agent__, and __ECS agent__ on those servers using that activation key
        - SSM Agent is used to manage and operate resources, and ECS Anywhere uses this agent to manage the on-prem VMs to orchestrate containers
    - define your app and deploy it the same way you would with ECS in AWS, and ECS can then manage them
- __Hybrid Cloud storage solutions__
    - __AWS Storage Gateway__
    - __AWS Backup__
        - for data-protection management
        - for compliance
        - apps running on AWS or on-prem!
        - __protect VMware workloads on AWS or on-prem, and data stored on AWS Storage Gateway volumes__
        - we choose __AWS Backup to manage their backups across environments__ for our use case
            - customer may or may not choose to use this eventually
- __Networking__
    - __AWS Direct Connect__
    - __Amazon Route 53 Resolver__
        - recursive DNS to Amazon VPC and on-prem network
- __Management__
    - Authentication and Authorization
        - __Amazon IAM__
        - __AWS Directory Service__
            - if you want to use Microsoft Active Directory to connect AWS and on-prem resources
    - __Monitoring__
        - __Amazon CloudWatch__
        - __AWS X-Ray__
            - runs on-prem or in a Docker container to relay trace data from your instrumented apps for debugging
    - __AWS Systems Manager__
        - __secure, end-to-end management solution for hybrid cloud__
        - manage and operate resources at scale
            - helps automating tasks
            - eg. if we have a massive fleet of servers both on AWS and on-prem, and we need to run the same script on all of these servers, we need to do so individually on each of them
                - time consuming
                - prone to human error
            - __Systems Manager feature__ called __Run Command__ makes this a lot easier
            - you can group instances (you can also use tag, or other metadata to group instances) using AWS Systems Manager (SSM), and run the script on them
            - __has lots of other features!__
        - https://aws.amazon.com/systems-manager/

## AWS Systems Manager Exploration
- __Four core feature groups__
    - __Operations Management__
        - Explorer
            - collect operational metrics and design dashboards (how is it different from CloudWatch??)
        - OpsCenter
        - CloudWatch Dashboard
        - Incident Manager
    - __Application Management__
        - Application Manager
        - AppConfig
            - to store feature flags, configuration data (eg. API throttle limits) etc.
        - Parameter Store
            - app parameter - eg. DB host etc. - supports encryption (helps to store secrets)
            - similar to __AWS Secrets Manager__ which is used to store secrets (API keys, DB connection credentials)
            - parameters can be used in commands (scripts), application code
    - __Change Management__
        - Automation
        - Change Manager
        - Maintenance Windows
            - schedule, implement and view statuses of maintenance tasks across your fleet
    - __Node Management__
        - Fleet Manager
        - Session Manager
        - Patch Manager
        - Run Command
            - scripts (commands aka __documents__) to run across your fleet without needing to SSH into instances
            - documents are in JSON format with shell scripts embedded in them

## Reading 3.5: AWS Services for Hybrid Deployments
- Amazon ECS Anywhere
    - use common tooling for running containers
- AWS Systems Manager
    - manage resources across environments
    - provide operational support and tasks
    - provides a unified UI to view operational data from multiple AWS services
    - group resources by application
        — such as EC2 instances, S3 buckets, or RDS instances — by application
    - __Verification and processing__
        - verifies that your AWS IAM user, group, or role has the needed permissions to perform the action that you specified
            - if the target of your action is a managed node, the SSM Agent that runs on the node performs the action
            - for other types of resources, Systems Manager performs the specified action or communicates with other AWS services to perform the action on behalf of Systems Manager
    - __Reporting__
        - the SSM Agent, and other AWS services that performed an action on behalf of Systems Manager report their status
            - Systems Manager can send status details to other AWS services, if configured
    - __Operations management__
        - Explorer, OpsCenter, and Incident Manager etc.
        — __aggregate operations data or create artifacts in response to events or errors__ with your resources
        - these artifacts include operational work items (__OpsItems__) and incidents
        - provide both operational insight into your apps and resources, and automated remediation solutions to troubleshoot problems
- AWS Backup
    - managing backups in one centralized place
    - automate data protection across AWS services and hybrid workloads
    - cost-effective, fully managed, policy-based service designed to simplify __data protection at scale__
    - supports your regulatory compliance or business policies for data protection
    - together with AWS Organizations, you can use AWS Backup to centrally deploy data protection policies to configure, manage, and govern your backup activity across your company's AWS accounts and resources
    - Supported resources include
        - EC2 instances
        - EBS volumes
        - S3 buckets
        - RDS databases
        - DynamoDB tables
        - Neptune databases
        - Amazon DocumentDB databases
        - EFS file systems
        - FSx
        - AWS Storage Gateway volumes
        - VMware workloads on premises, on Amazon Outposts, and in VMware Cloud on AWS

## Customer #3: Solution Overview
- container registry
    - ECR or Docker Hub can be used

## Week Wrap-Up: Taking this Architecture to the Next Level
- Along with Direct Connect have VPN for failover
- Can enable Storage Auto-scaling on RDS
- Cross-region RDS
    - use DMS for continuous replication from primary region to secondary
- Cross-region read replicas
    - PostgreSQL on RDS support it
- Secondary AWS region for similar infrastructure (multi-regions)
    - Need IaC
    - to save costs you don't need the entire infrastructure
        - you can have a scaled-down version of the EC2 fleet
- Enabling S3 lifecycle policies (intelligent tiering) and S3 cross-region replication
- EC2 fleet needs scaling set up
    - usually this is done with EC2 auto-scaling
    - but, ECS has it own scaling mechanism as well
        - so we need to consider this to set up auto-scaling

## Reading 3.6: Architecture Optimizations for Week 3
- __Disaster Recovery (DR)__
- The __DR strategies__ that are available to you within AWS
    - range from the __low cost and low complexity of making backups__ to __more complex strategies that use multiple active Regions__
    - classified as __active/passive strategies__ - use an active site (such as an AWS Region) to host the workload and serve traffic. The passive site (such as a different AWS Region) is used for recovery
        - The passive site does not actively serve traffic until a failover event is triggered
- __DR Strategies__
    - __Backup and restore__
        - suitable approach for mitigating against data loss or corruption
        - mitigate against a regional disaster by replicating data to other AWS Regions, or to mitigate a lack of redundancy for workloads that are deployed to a single AZ
        - use __IaC__ to also replicate __infrastructure__, __configuration__, and __application code__
            - __AWS CloudFormation__, __AWS Cloud Development Kit (AWS CDK)__ can be used to redeploy __infrastructure__
            - __AWS CodePipeline__ to automate the redeployment of your __application code__ and __configurations__
        - core infrastructure is anot always available - provision resources only after the disaster!
    - __Pilot light__
        - you replicate your data from one Region to another
        - provision a copy of your core workload infrastructure
            - resources that are needed to support data replication and backup — such as __DBs and object storage, are always on__
            - __other elements (such as application servers) are loaded with application code and configurations, but are turned off__
            - unlike the backup and restore approach, your __core infrastructure is always available__
    - __Warm standby__
        - provision a scaled down, but fully functional copy of your production environment in another Region
        - extends the pilot-light concept and decreases the time to recovery because your workload is always-on in another Region
    - __Multi-site active/active__
        - run your workload simultaneously in multiple Regions as part of __either a multi-site active/active strategy__ or a __hot standby active/passive strategy__
            - __multi-site active/active approach__ serves traffic from all Regions where it's deployed
                - most complex and most costly
                - it can reduce your recovery time to near zero, with the correct technology choices and implementation
                - data corruption might still need to rely on backups, which usually results in a non-zero recovery point
            - __hot standby approach__ serves traffic from only a single Region, and the other Regions are used only for DR
                - uses an active/passive configuration
                - most customers find it active/active approach more useful in practice
- __AWS Direct Connect with AWS VPN for failover__
    - the customer can consider using Amazon Site-to-Site VPN as a failover for AWS Direct Connect so that the connection is redundant
- __Automatic scaling for containers__
    - when using ECS, we need to ourselves think about scaling both their underlying EC2 cluster and the containers
    - __Scaling the cluster using _ECS cluster auto scaling___
        - ECS can manage the scaling of EC2 instances that are registered to the cluster, based on the load that your tasks put on your cluster
        - performed by an __ECS ASG capacity provider__ that has managed scaling turned on
        - ECS creates 2 custom Amazon CloudWatch metrics, and a target tracking scaling policy that attaches to your ASG
    - __Scaling the containers__
        - ability to increase or decrease the desired count of tasks in your Amazon ECS service automatically
        - ECS uses the __Application Auto Scaling service__ to provide this functionality
        - you can optionally configure ECS to automatically scale (up/down) its desired count of tasks in response to CloudWatch alarms
        - ECS Service Auto Scaling supports the following types of scaling policies
            - __Target tracking scaling policies (Recommended)__
                - Increase or decrease the number of tasks that your service runs, based on a target value for a specific metric
                - This scaling approach is similar to the way that your thermostat maintains the temperature of your home. You select the temperature, and the thermostat manages the temperature
            - __Step scaling policies__
                - Increase or decrease the number of tasks that your service runs, based on a set of scaling adjustments, which are also known as step adjustments
                - These adjustments vary based on the size of the alarm breach
- __Automatic scaling for Amazon RDS__
    - when storage autoscaling is enabled, RDS can automatically scales up your storage when it detects that you are running out of space
- __Amazon S3 Intelligent-Tiering__
    - automatically moving data to the most cost-effective access tier when access patterns change

## Resources
- [Network-to-Amazon VPC connectivity options](https://docs.aws.amazon.com/whitepapers/latest/aws-vpc-connectivity-options/network-to-amazon-vpc-connectivity-options.html)
- [What is AWS Direct Connect?](https://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html)
- [AWS Direct Connect FAQs](https://aws.amazon.com/directconnect/faqs/)
- [What is Amazon Site-to-Site VPN?](https://docs.aws.amazon.com/vpn/latest/s2svpn/VPC_VPN.html)
- [What is AWS Client VPN?](https://docs.aws.amazon.com/vpn/latest/clientvpn-admin/what-is.html)
- [What is a transit gateway?](https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html)
- [Containers at AWS](https://aws.amazon.com/containers/)
- [Customers FAQs on the AWS Containers site](https://aws.amazon.com/containers/faqs/)
- [Amazon ECS launch types](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/launch_types.html)
- [Connect to the internet or other networks using NAT devices](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat.html)
- [Compare NAT gateways and NAT instances](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html)
- [AWS Database Migration Service](https://aws.amazon.com/dms/)
- [Amazon RDS Multi-AZ](https://aws.amazon.com/rds/features/multi-az/)
- [Amazon RDS Read Replicas](https://aws.amazon.com/rds/features/read-replicas/)
- [Amazon RDS DB instances](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.html)
- [What is AWS Database Migration Service?](https://docs.aws.amazon.com/dms/latest/userguide/Welcome.html)
- [AWS Storage Gateway](https://aws.amazon.com/storagegateway/)
- [What is Amazon S3 File Gateway?](https://docs.aws.amazon.com/filegateway/latest/files3/what-is-file-s3.html)
- [AWS Storage Gateway Features](https://aws.amazon.com/storagegateway/features/)
- [Amazon EBS volume types](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html)
- [What is Amazon EFS?](https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html)
- [What is Amazon S3?](https://docs.aws.amazon.com/AmazonS3/latest/userguide//Welcome.html)
- [Getting Started with Amazon S3](https://aws.amazon.com/s3/getting-started/)
- [Amazon S3 Storage Classes](https://aws.amazon.com/s3/storage-classes/)
- [Hybrid Cloud with AWS](https://aws.amazon.com/hybrid/)
- [AWS Systems Manager](https://aws.amazon.com/systems-manager/)
- [Amazon ECS Workshop: ECS Anywhere](https://www.ecsworkshop.com/ecsanywhere/)
- [Remotely Run Commands on an EC2 Instance with AWS Systems Manager](https://aws.amazon.com/getting-started/hands-on/remotely-run-commands-ec2-instance-systems-manager/)
- [AWS Management and Governance Tools Workshop: AWS Systems Manager](https://mng.workshop.aws/ssm.html)
- [What is AWS Systems Manager?](https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html)
- [What is AWS Backup?](https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html)
- [Amazon Machine Images (AMIs)](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)
- [AWS CodePipeline](https://aws.amazon.com/codepipeline/)
- [Disaster Recovery of Workloads on AWS: Recovery in the Cloud](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-workloads-on-aws.html)
- [How do I configure Direct Connect and VPN failover with Transit Gateway?](https://repost.aws/knowledge-center/dx-configure-dx-and-vpn-failover-tgw)
- [Amazon ECS cluster Auto Scaling](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html)
- [Amazon ECS Workshop: Deploy ECS Cluster Auto Scaling](https://ecsworkshop.com/capacity_providers/ec2/)
- [Service auto scaling](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
- [Managing capacity automatically with Amazon RDS storage autoscaling](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS.Autoscaling)
- [Amazon S3 Intelligent-Tiering storage class](https://aws.amazon.com/s3/storage-classes/intelligent-tiering/)
- []()